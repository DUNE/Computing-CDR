{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Externals, Note use of commentjson\n",
    "\n",
    "Version 5 - stop using maps layers for multiple things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,string,time,commentjson,datetime\n",
    "from csv import reader\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility function: object = cummulate(object,lifetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum backwards over lifetime of record\n",
    "def cumulate(a,lifetime=100):\n",
    "  if lifetime < 1:\n",
    "    return a*lifetime\n",
    "  b = np.zeros(len(a))\n",
    "  for i in range(0,len(a)):\n",
    "    begin = max(0,i-lifetime+1)\n",
    "    for j in range(begin,i+1):\n",
    "      b[i] += a[j]\n",
    "  return b\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility function: string = dump(datatype,det,object,Units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NumberUtils import dump\n",
    "from NumberUtils import DrawTex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility function: DrawDet(Value,Years,Data,Types,Units,detcolors,detlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NumberUtils import DrawDet  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility function: DrawType(Value,Years,Data,Types,Units,typecolors,typelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw by data type (transpose of the detectors)\n",
    "from NumberUtils import DrawType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the config file \"Parameters2040.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get parameters into config\n",
    "\n",
    "configfile = \"Parameters_2021-04-28-EB-copy.json\"\n",
    "#configfile = \"Parameters_2040.json\"\n",
    "if os.path.exists(configfile):\n",
    "  with open(configfile,'r') as f:\n",
    "    config = commentjson.load(f)\n",
    "else:\n",
    "  print (\"no config file\",configfile)\n",
    "  sys.exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the json file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_formatted_str = commentjson.dumps(config, indent=2)\n",
    "\n",
    "#print(json_formatted_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Set up parameters from input file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tape FNAL Raw 0.5\n",
      "Tape CERN Raw 0.5\n",
      "Tape Collab Raw 0.0\n",
      "Tape FNAL Sim 0.75\n",
      "Tape CERN Sim 0.0\n",
      "Tape Collab Sim 0.25\n",
      "Tape FNAL Reco 0.75\n",
      "Tape CERN Reco 0.0\n",
      "Tape Collab Reco 0.25\n",
      "Tape FNAL Test 0.5\n",
      "Tape CERN Test 0.5\n",
      "Tape Collab Test 0.0\n",
      "Disk FNAL Raw 0.5\n",
      "Disk CERN Raw 0.5\n",
      "Disk Collab Raw 0.0\n",
      "Disk FNAL Sim 0.25\n",
      "Disk CERN Sim 0.0\n",
      "Disk Collab Sim 0.75\n",
      "Disk FNAL Reco 0.25\n",
      "Disk CERN Reco 0.0\n",
      "Disk Collab Reco 0.75\n",
      "Disk FNAL Test 0.5\n",
      "Disk CERN Test 0.5\n",
      "Disk Collab Test 0.0\n"
     ]
    }
   ],
   "source": [
    "# set up shortcuts for parameters\n",
    "\n",
    "MaxYears = config[\"MaxYears\"]\n",
    "MinYears = config[\"MinYears\"]\n",
    "Years = np.array(config[\"Years\"][0:MaxYears])\n",
    "size = len(Years)\n",
    "\n",
    "Units = config[\"Units\"]\n",
    "\n",
    "Detectors = config[\"Detectors\"]\n",
    "\n",
    "CombinedDetectors = config[\"CombinedDetectors\"]\n",
    "\n",
    "DetectorParameters = list(config[\"SP\"].keys())\n",
    "\n",
    "TapeLifetimes = config[\"TapeLifetimes\"]\n",
    "\n",
    "DiskLifetimes = config[\"DiskLifetimes\"]\n",
    "\n",
    "TapeCopies = config[\"TapeCopies\"]\n",
    "\n",
    "DiskCopies = config[\"DiskCopies\"]\n",
    "\n",
    "RecoMemory = config[\"RecoMemory\"]\n",
    "\n",
    "SplitsEarly = config[\"SplitsEarly\"]\n",
    "SplitsLater = config[\"SplitsLater\"]\n",
    "Splits = {}\n",
    "for f in SplitsEarly:\n",
    "    Splits[f] = {}\n",
    "    for t in SplitsEarly[f]:\n",
    "        Splits[f][t] = {}\n",
    "        for loc in SplitsEarly[f][t]: \n",
    "           # Splits[f][t][loc] = {}\n",
    "            print (f,loc,t,SplitsEarly[f][t][loc])\n",
    "            Splits[f][t][loc] = np.zeros(len(Years))\n",
    "            #print (f,t,Splits[f][t],Splits[f][t][0])\n",
    "    \n",
    "            for y in range(0,len(Years)):\n",
    "                if y < 9:\n",
    "                    #print (\"test\",f, t, y, Splits[f][t][y],SplitsEarly[f][t])\n",
    "                    Splits[f][t][loc][y]=SplitsEarly[f][t][loc]\n",
    "                else:\n",
    "                    Splits[f][t][loc][y]=SplitsLater[f][t][loc]\n",
    "\n",
    "#print (Splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Raw': 100, 'Test': 0.5, 'Reco': 15, 'Sim': 15}\n",
      "\\documentclass[12pt]{article}\n",
      "\\usepackage{graphicx}\n",
      "\\begin{document}\n",
      "\\parindent=0pt\n",
      "\\setlength{\\textwidth=7.0 in}\n",
      "\\setlength{\\oddsidemargin=0.00 in}\n",
      "\\setlength{\\topmargin=0 in}\n",
      "\\setlength{\\textheight=9.5 in}\n",
      "\n",
      "\\centerline{\\bf{DUNE Resource Report}}\\vskip 1 in \\par Configuration: Parameters_2021-04-28-EB-copy.json\n",
      "Date: 2021-07-25 16:30TZ\n",
      " \n",
      "\n",
      "Fiscal year starts: April 1\n",
      "Tape is accounted for at: end of fiscal year\n",
      "Disk is accounted for on: October 1\n",
      "CPU is accounted for at: end of fiscal year\n",
      "\n",
      "Reco passes per Year: 1\n",
      "Sim passes per Year: 1\n",
      "Analysis relative to Sim+Reco: 1\n",
      "\n",
      "\n",
      "{\\bf For data type Raw}\n",
      "   Raw Tape lifetime 100.0 in years\n",
      "   Raw Tape Copies   2.0\n",
      "   Raw FNAL Tape fraction for PD  0.50\n",
      "   Raw FNAL Tape fraction for DUNE  0.50\n",
      "   Raw CERN Tape fraction for PD  0.50\n",
      "   Raw CERN Tape fraction for DUNE  0.00\n",
      "   Raw Collaboration Tape fraction for PD  0.00\n",
      "   Raw Collaboration Tape fraction for DUNE  0.50\n",
      "   Raw Disk lifetime   1.0 in years\n",
      "   Raw Disk Copies   1.0\n",
      "   Raw FNAL Disk fraction for PD  0.50\n",
      "   Raw FNAL Disk fraction for DUNE  1.00\n",
      "   Raw CERN Disk fraction for PD  0.50\n",
      "   Raw CERNDisk fraction for DUNE  0.00\n",
      "   Raw Collaboration Disk fraction for PD  0.00\n",
      "   Raw Collaboration Disk fraction for DUNE  0.00\n",
      "\n",
      "{\\bf For data type Test}\n",
      "  Test Tape lifetime   0.5 in years\n",
      "  Test Tape Copies   1.0\n",
      "  Test FNAL Tape fraction for PD  0.50\n",
      "  Test FNAL Tape fraction for DUNE  0.50\n",
      "  Test CERN Tape fraction for PD  0.50\n",
      "  Test CERN Tape fraction for DUNE  0.00\n",
      "  Test Collaboration Tape fraction for PD  0.00\n",
      "  Test Collaboration Tape fraction for DUNE  0.50\n",
      "  Test Disk lifetime   0.5 in years\n",
      "  Test Disk Copies   0.5\n",
      "  Test FNAL Disk fraction for PD  0.50\n",
      "  Test FNAL Disk fraction for DUNE  0.50\n",
      "  Test CERN Disk fraction for PD  0.50\n",
      "  Test CERNDisk fraction for DUNE  0.00\n",
      "  Test Collaboration Disk fraction for PD  0.00\n",
      "  Test Collaboration Disk fraction for DUNE  0.50\n",
      "\n",
      "{\\bf For data type Reco}\n",
      "  Reco Tape lifetime  15.0 in years\n",
      "  Reco Tape Copies   1.0\n",
      "  Reco FNAL Tape fraction for PD  0.75\n",
      "  Reco FNAL Tape fraction for DUNE  0.50\n",
      "  Reco CERN Tape fraction for PD  0.00\n",
      "  Reco CERN Tape fraction for DUNE  0.00\n",
      "  Reco Collaboration Tape fraction for PD  0.25\n",
      "  Reco Collaboration Tape fraction for DUNE  0.50\n",
      "  Reco Disk lifetime   2.0 in years\n",
      "  Reco Disk Copies   2.0\n",
      "  Reco FNAL Disk fraction for PD  0.25\n",
      "  Reco FNAL Disk fraction for DUNE  0.25\n",
      "  Reco CERN Disk fraction for PD  0.00\n",
      "  Reco CERNDisk fraction for DUNE  0.00\n",
      "  Reco Collaboration Disk fraction for PD  0.75\n",
      "  Reco Collaboration Disk fraction for DUNE  0.75\n",
      "\n",
      "{\\bf For data type Sim}\n",
      "   Sim Tape lifetime  15.0 in years\n",
      "   Sim Tape Copies   1.0\n",
      "   Sim FNAL Tape fraction for PD  0.75\n",
      "   Sim FNAL Tape fraction for DUNE  0.50\n",
      "   Sim CERN Tape fraction for PD  0.00\n",
      "   Sim CERN Tape fraction for DUNE  0.00\n",
      "   Sim Collaboration Tape fraction for PD  0.25\n",
      "   Sim Collaboration Tape fraction for DUNE  0.50\n",
      "   Sim Disk lifetime   2.0 in years\n",
      "   Sim Disk Copies   2.0\n",
      "   Sim FNAL Disk fraction for PD  0.25\n",
      "   Sim FNAL Disk fraction for DUNE  0.25\n",
      "   Sim CERN Disk fraction for PD  0.00\n",
      "   Sim CERNDisk fraction for DUNE  0.00\n",
      "   Sim Collaboration Disk fraction for PD  0.75\n",
      "   Sim Collaboration Disk fraction for DUNE  0.75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PerYear = config[\"PerYear\"]\n",
    "print (TapeLifetimes)\n",
    "table = open(configfile.replace(\"json\",\"txt\"),'w')\n",
    "\n",
    "tex = open(configfile.replace(\"json\",\"tex\"),'w')\n",
    "s = \"\\\\documentclass[12pt]{article}\\n\\\\usepackage{graphicx}\\n\"\n",
    "s += \"\\\\begin{document}\\n\\\\parindent=0pt\\n\\\\setlength{\\\\textwidth=7.0 in}\\n\"\n",
    "s += \"\\\\setlength{\\\\oddsidemargin=0.00 in}\\n\"\n",
    "s += \"\\\\setlength{\\\\topmargin=0 in}\\n\"\n",
    "s += \"\\\\setlength{\\\\textheight=9.5 in}\\n\"\n",
    "print(s)\n",
    "tex.write(s)\n",
    "s = \"\\\\centerline{\\\\bf{DUNE Resource Report}}\\\\vskip 1 in \\\\par Configuration: %s\\nDate: %sTZ\\n \\n\"%(configfile,(datetime.datetime.utcnow().strftime(\"%Y-%m-%d %H:%M\")))\n",
    "print(s)\n",
    "table.write(s)\n",
    "tex.write(s.replace(\"_\",\"\\_\").replace(\"\\n\",\"\\\\\\\\  \"))\n",
    "#tex.write(\"\\hline\\n\")\n",
    "\n",
    "s = \"Fiscal year starts: %s\\nTape is accounted for at: %s\\nDisk is accounted for on: %s\\nCPU is accounted for at: %s\\n\"%\\\n",
    "(config[\"FiscalYearStart\"],config[\"Tape Accounting\"],config[\"Disk Accounting\"],config[\"CPU Accounting\"])\n",
    "table.write(s)\n",
    "print(s)\n",
    "tex.write(s.replace(\"\\n\",\"\\\\\\\\ \\n\"))\n",
    "\n",
    "s = \"Reco passes per Year: %s\\nSim passes per Year: %s\\nAnalysis relative to Sim+Reco: %s\\n\"%(PerYear[\"CPU\"],PerYear[\"Sim-CPU\"],config[\"Analysis\"][\"Scale\"])\n",
    "table.write(s)\n",
    "print(s)\n",
    "tex.write(s.replace(\"\\n\",\"\\\\\\\\\\n\"))\n",
    "\n",
    "tex.write(\"\\\\pagebreak\\n\")\n",
    "s = \"\"\n",
    "for type in TapeLifetimes:\n",
    "    s += \"\\n{\\\\bf For data type %s}\\n\"%type\n",
    "   # print (s)\n",
    "   # table.write(s)\n",
    "    s += \"%6s Tape lifetime %5.1f in years\\n\"%(type,TapeLifetimes[type])\n",
    "   # print (s)\n",
    "   # table.write(s)\n",
    "    s += \"%6s Tape Copies %5.1f\\n\"%(type,TapeCopies[type])\n",
    "   # print (s)\n",
    "  #  table.write(s)\n",
    "    s += \"%6s FNAL Tape fraction for PD %5.2f\\n\"%(type,SplitsEarly[\"Tape\"][type][\"FNAL\"])\n",
    "    s += \"%6s FNAL Tape fraction for DUNE %5.2f\\n\"%(type,SplitsLater[\"Tape\"][type][\"FNAL\"])\n",
    "    s += \"%6s CERN Tape fraction for PD %5.2f\\n\"%(type,SplitsEarly[\"Tape\"][type][\"CERN\"])\n",
    "    s += \"%6s CERN Tape fraction for DUNE %5.2f\\n\"%(type,SplitsLater[\"Tape\"][type][\"CERN\"])\n",
    "    s += \"%6s Collaboration Tape fraction for PD %5.2f\\n\"%(type,SplitsEarly[\"Tape\"][type][\"Collab\"])\n",
    "    s += \"%6s Collaboration Tape fraction for DUNE %5.2f\\n\"%(type,SplitsLater[\"Tape\"][type][\"Collab\"])\n",
    "   # print (s)\n",
    "  #  table.write(s)\n",
    "    s += \"%6s Disk lifetime %5.1f in years\\n\"%(type,DiskLifetimes[type])\n",
    "   # print (s)\n",
    "  #  table.write(s)\n",
    "    s += \"%6s Disk Copies %5.1f\\n\"%(type,DiskCopies[type])\n",
    "   # print (s)\n",
    "  #  table.write(s)\n",
    "    s += \"%6s FNAL Disk fraction for PD %5.2f\\n\"%(type,SplitsEarly[\"Disk\"][type][\"FNAL\"])\n",
    "    s += \"%6s FNAL Disk fraction for DUNE %5.2f\\n\"%(type,SplitsLater[\"Disk\"][type][\"FNAL\"])\n",
    "    s += \"%6s CERN Disk fraction for PD %5.2f\\n\"%(type,SplitsEarly[\"Disk\"][type][\"CERN\"])\n",
    "    s += \"%6s CERNDisk fraction for DUNE %5.2f\\n\"%(type,SplitsLater[\"Disk\"][type][\"CERN\"])\n",
    "    s += \"%6s Collaboration Disk fraction for PD %5.2f\\n\"%(type,SplitsEarly[\"Disk\"][type][\"Collab\"])\n",
    "    s += \"%6s Collaboration Disk fraction for DUNE %5.2f\\n\"%(type,SplitsLater[\"Disk\"][type][\"Collab\"])\n",
    "  #  print (s)\n",
    "  #  table.write(s)\n",
    "    \n",
    "print(s)\n",
    "table.write(s)\n",
    "tex.write(s.replace(\"\\n\",\"\\\\\\\\\\n\"))\n",
    "\n",
    "#table.write(\"Calendar Years\")\n",
    "    \n",
    "StorageTypes = list(TapeCopies.keys())\n",
    "\n",
    "# plot config\n",
    "DetColors=config[\"DetColors\"]\n",
    "DetLines = config[\"DetLines\"]\n",
    "TypeColors=config[\"TypeColors\"]\n",
    "TypeLines = config[\"TypeLines\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make data structures - Inputs and Data \n",
    "\n",
    "Data[type][det] is an dictionary keyed on type and detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thetypes ['Events', 'Sim Events', 'Test']\n",
      "thedets ['SP', 'DP', 'FD', 'ND']\n",
      "size SP Events {'Events': array([10.9, 19.4,  6.5,  6.5, 43.5, 20. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
      "        0. ])}\n",
      "size SP Sim Events {'Events': array([ 1.25,  5.  ,  5.  , 10.  , 20.  , 20.  , 20.  ,  5.  ,  0.  ,\n",
      "        0.  ,  0.  ,  0.  ])}\n",
      "size SP Test {'Events': array([ 157.  ,  600.  ,  500.  ,  769.23, 3346.15,  500.  ,  500.  ,\n",
      "        500.  ,    0.  ,    0.  ,    0.  ,    0.  ])}\n",
      "size DP Events {'Events': array([ 0. ,  0.5,  0.9,  2. , 10. , 10. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
      "        0. ])}\n",
      "size DP Sim Events {'Events': array([1.25, 5.  , 5.  , 5.  , 5.  , 5.  , 5.  , 5.  , 0.  , 0.  , 0.  ,\n",
      "       0.  ])}\n",
      "size DP Test {'Events': array([  0,  42, 500, 231, 231, 231, 500, 500,   0,   0,   0,   0])}\n",
      "size FD Events {'Events': array([0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 2.2, 2.2])}\n",
      "size FD Sim Events {'Events': array([ 0,  0,  0,  0,  0,  0,  0,  0, 10, 10, 10, 10])}\n",
      "size FD Test {'Events': array([    0,     0,     0,     0,     0,     0,     0,     0,  1500,\n",
      "       10500, 10500, 12000])}\n",
      "size ND Events {'Events': array([ 0,  0,  0,  0, 10, 10,  0,  0,  0,  0,  0, 25])}\n",
      "size ND Sim Events {'Events': array([  0,   0,  10,  25,  10,  10,  10,  10,  50,  50, 100, 100])}\n",
      "size ND Test {'Events': array([  0,   0,   0,   0, 300, 300,   0,   0,   0,   0,   0, 500])}\n"
     ]
    }
   ],
   "source": [
    "# build the inputs array\n",
    "\n",
    "Inputs = {}\n",
    "PatternFraction = config[\"PatternFraction\"]\n",
    "# get in the input values (Events and amount of commissioning in TB)\n",
    " \n",
    "# these variables are set in the json \n",
    "\n",
    "\n",
    "\n",
    "thetypes = config[\"DataTypes\"]\n",
    "print (\"thetypes\",thetypes)\n",
    "thedets = config[\"Detectors\"]\n",
    "print (\"thedets\",thedets)\n",
    "\n",
    "for det in thedets:\n",
    "  Inputs[det]={}\n",
    "  for type in thetypes:\n",
    "    Inputs[det][type]={}\n",
    "    Inputs[det][type][\"Events\"] = np.array(config[det][type])\n",
    "    Inputs[det][type][\"Events\"].resize(MaxYears)\n",
    "     \n",
    "    print (\"size\", det,type, Inputs[det][type])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key SP Events Raw\n",
      "key SP Events CPU\n",
      "key SP Events Reco\n",
      "key SP Sim Events Raw\n",
      "key SP Sim Events CPU\n",
      "key SP Sim Events Reco\n",
      "key SP Test Raw\n",
      "key SP Test CPU\n",
      "key SP Test Reco\n",
      "key DP Events Raw\n",
      "key DP Events CPU\n",
      "key DP Events Reco\n",
      "key DP Sim Events Raw\n",
      "key DP Sim Events CPU\n",
      "key DP Sim Events Reco\n",
      "key DP Test Raw\n",
      "key DP Test CPU\n",
      "key DP Test Reco\n",
      "key FD Events Raw\n",
      "key FD Events CPU\n",
      "key FD Events Reco\n",
      "key FD Sim Events Raw\n",
      "key FD Sim Events CPU\n",
      "key FD Sim Events Reco\n",
      "key FD Test Raw\n",
      "key FD Test CPU\n",
      "key FD Test Reco\n",
      "key ND Events Raw\n",
      "key ND Events CPU\n",
      "key ND Events Reco\n",
      "key ND Sim Events Raw\n",
      "key ND Sim Events CPU\n",
      "key ND Sim Events Reco\n",
      "key ND Test Raw\n",
      "key ND Test CPU\n",
      "key ND Test Reco\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use those to calculate CPU and space needs\n",
    "    \n",
    "for det in Detectors:\n",
    "  for atype in thetypes:  \n",
    "      for key in DetectorParameters:\n",
    "        if \"Events\" in key or \"Test\" in key:\n",
    "            continue\n",
    "        # skip the ones already done\n",
    "        #if key in thetypes:\n",
    "        #  continue\n",
    "        # sim has its own configuration \n",
    "        if not \"Sim\" in key:\n",
    "          print(\"key\",det,atype,key)      \n",
    "          if key in [\"CPU\",\"Reco\"]:  # if doing data reco, do over previous events using memory\n",
    "                Inputs[det][atype][key] = cumulate(Inputs[det][atype][\"Events\"],RecoMemory[det])*config[det][key]\n",
    "\n",
    "          else:\n",
    "                Inputs[det][atype][key]=Inputs[det][\"Events\"][\"Events\"]*config[det][key]\n",
    "        else:\n",
    "          Inputs[det][atype][key]=Inputs[det][\"Sim Events\"][\"Events\"]*config[det][key]\n",
    "\n",
    "# write some of this out\n",
    "#print (Inputs[\"ND\"])\n",
    "o = open(\"out.csv\",'w')\n",
    "o.write(dump(\"Year\",\"Years\",Years,Units))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Events SP 1 {'Events': array([10.9, 19.4,  6.5,  6.5, 43.5, 20. ,  0. ,  0. ,  0. ,  0. ,  0. ,\n",
      "        0. ]), 'Raw': array([ 763., 1358.,  455.,  455., 3045., 1400.,    0.,    0.,    0.,\n",
      "          0.,    0.,    0.]), 'CPU': array([ 1.81703,  5.05101,  6.13456,  5.40108,  9.41855, 11.669  ,\n",
      "       10.58545,  3.334  ,  0.     ,  0.     ,  0.     ,  0.     ]), 'Sim-CPU': array([ 0.9375,  3.75  ,  3.75  ,  7.5   , 15.    , 15.    , 15.    ,\n",
      "        3.75  ,  0.    ,  0.    ,  0.    ,  0.    ]), 'Reco': array([ 381.5, 1060.5, 1288. , 1134. , 1977.5, 2450. , 2222.5,  700. ,\n",
      "          0. ,    0. ,    0. ,    0. ]), 'Sim': array([ 275., 1100., 1100., 2200., 4400., 4400., 4400., 1100.,    0.,\n",
      "          0.,    0.,    0.])}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'dict' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e4c34b9f36b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPerYear\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mInputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdet\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# this allows you to, say, do 2 passes of reco/year\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdet\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdet\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPerYear\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;31m# compensate for nominal units being millions and TB or singles and MB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUnits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"PB\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'dict' and 'float'"
     ]
    }
   ],
   "source": [
    "# use inputs to calculate per year sizes and store in transposed map Data\n",
    "if PerYear[\"Reco\"]!=PerYear[\"CPU\"]:\n",
    "    print (\"Data growth has to match reprocessing cycles/year\")\n",
    "    PerYear[\"Reco\"] = PerYear[\"CPU\"]\n",
    "if PerYear[\"Sim\"]!=PerYear[\"Sim-CPU\"]:\n",
    "    print (\"Sim growth has to match reprocessing cycles/year\")\n",
    "    PerYear[\"Sim\"] = PerYear[\"Sim-CPU\"]\n",
    "    \n",
    "Data = {}\n",
    "#print (Inputs.keys())\n",
    "for dtype in Inputs[\"ND\"].keys():\n",
    "  Data[dtype] = {} \n",
    "  #Data[\"Full-Reco\"] = {}\n",
    "  for det in Inputs.keys():\n",
    "    print (dtype,det,PerYear[dtype],Inputs[det][dtype])\n",
    "    \n",
    "    # this allows you to, say, do 2 passes of reco/year\n",
    "    Data[dtype][det] = Inputs[det][dtype] * float(PerYear[dtype])  \n",
    "    # compensate for nominal units being millions and TB or singles and MB\n",
    "    if Units[dtype] == \"PB\":\n",
    "      Data[dtype][det] *= 0.001\n",
    "    o.write(dump(det,dtype,Data[dtype][det],Units))\n",
    "    \n",
    "# replace Reco with reconstruction over previous years\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For FD and ND assume reprocess full sample when get new reco version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (\"types\",Data.keys())\n",
    "#print (\"detectors\", Data[\"Events\"].keys())\n",
    "print (\"values\", Data[\"Events\"][\"FD\"])#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now draw the # of events/year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DrawDet(\"Events\",Years,Data,Inputs.keys(),Units,DetColors,DetLines)\n",
    "#DrawDet(\"CPU\",Years,Data,Inputs.keys(),Units,DetColors,DetLines)\n",
    "DrawDet(\"CPU\",Years,Data,Inputs.keys(),Units,DetColors,DetLines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the protoDUNEs into one and replace them in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine ProtoDUNEs into one and get rid of SP and DP\n",
    " \n",
    " \n",
    "for dtype in Data.keys():\n",
    "  det = \"ProtoDUNE\"\n",
    "  #print (dtype)\n",
    "  Data[dtype][det] = Data[dtype][\"SP\"] + Data[dtype][\"DP\"]\n",
    "  Data[dtype].pop(\"SP\")\n",
    "  Data[dtype].pop(\"DP\")\n",
    "\n",
    "  o.write(dump(det,dtype,Data[dtype][det],Units))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a Total-CPU datatype, and a Total \"detector\" which sums over detectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a total CPU sub-category\n",
    "\n",
    "Data[\"Total-CPU\"]={}\n",
    "#Data[\"Data-CPU\"]={}\n",
    "\n",
    "for det in CombinedDetectors:\n",
    "  Data[\"Total-CPU\"][det] =  Data[\"CPU\"][det] + Data[\"Sim-CPU\"][det]\n",
    " # Data[\"Data-CPU\"][det] = Data[\"CPU\"][det]\n",
    "  \n",
    "#Data.pop(\"CPU\")\n",
    "# sum up data across detectors.\n",
    "\n",
    "DataTypes = list(Data.keys())\n",
    "print (DataTypes)\n",
    "\n",
    "for dt in DataTypes:\n",
    "  Data[dt][\"Total\"] = np.zeros(size)\n",
    "  for k in Data[dt].keys():\n",
    "    if k == \"Total\":\n",
    "      continue\n",
    "    Data[dt][\"Total\"] += Data[dt][k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make an Analysis \"detector\" that scales with sum of CPU use for all detectors them and add into Total-CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume analysis CPU = some multiplier of total sim + reco\n",
    "\n",
    "Data[\"Total-CPU\"][\"Analysis\"]= np.zeros(size)\n",
    "for det in config[\"Analysis\"][\"Add\"]:\n",
    "    # scale allows you to change the scale of analysis relative to reconstruction and simulations\n",
    "  Data[\"Total-CPU\"][\"Analysis\"]+= Data[\"Total-CPU\"][det]*config[\"Analysis\"][\"Scale\"]\n",
    "\n",
    "  \n",
    "o.write(dump(\"Analysis\",\"Total-CPU\",Data[\"Total-CPU\"][\"Analysis\"],Units))\n",
    "  \n",
    "# and put it in the total\n",
    "\n",
    "Data[\"Total-CPU\"][\"Total\"] += Data[\"Total-CPU\"][\"Analysis\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a Cores type that is just CPU scaled to a 2020 CPU with some efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and make a special data type for cores\n",
    "\n",
    "Data[\"Cores\"] = {}\n",
    "Data[\"SPEC06\"] = {}\n",
    "MHrsPerYear = 1000000./365/24\n",
    "for k in Data[\"Total-CPU\"].keys():\n",
    "  efficiency = config[\"Cores\"][\"Efficiency\"]\n",
    "  scaleTo2020 = config[\"Cores\"][\"2020Units\"]\n",
    "  Data[\"Cores\"][k] = Data[\"Total-CPU\"][k]*MHrsPerYear/efficiency/scaleTo2020\n",
    "  Data[\"SPEC06\"][k] = Data[\"Total-CPU\"][k]*MHrsPerYear/efficiency/scaleTo2020*config[\"kHEPSPEC06PerCPU\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# write out the totals\n",
    "\n",
    "for k in Data.keys():\n",
    "  #print (\"total:\",k,Units[k], Data[k][\"Total\"])\n",
    "  o.write(dump(\"Total\",k,Data[k][\"Total\"],Units))\n",
    "  for i in Data[k].keys():\n",
    "    print(k,i,Data[k][i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the data lifetimes and # of copies to sum up cumulative amounts for disk and tape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# now do some cumulative work.  Stuff stays on tape/disk for different amounts of time and we have multiple copies\n",
    "\n",
    "Data[\"Total\"] = {}\n",
    "Data[\"Collab\"] = {}\n",
    "Data[\"FNAL\"] = {}\n",
    "Data[\"CERN\"] = {}\n",
    "Data[\"Total\"][\"Cumulative Tape\"] = 0\n",
    "Data[\"Total\"][\"Cumulative Disk\"] = 0\n",
    "Data[\"FNAL\"][\"Cumulative Tape\"] = 0\n",
    "Data[\"FNAL\"][\"Cumulative Disk\"] = 0\n",
    "Data[\"CERN\"][\"Cumulative Tape\"] = 0\n",
    "Data[\"CERN\"][\"Cumulative Disk\"] = 0\n",
    "Data[\"Collab\"][\"Cumulative Tape\"] = 0\n",
    "Data[\"Collab\"][\"Cumulative Disk\"] = 0\n",
    "print (\"Storage types\",StorageTypes)\n",
    "\n",
    "\n",
    "for k in StorageTypes:\n",
    "  Data[k][\"Tape\"] = Data[k][\"Total\"]*TapeCopies[k]\n",
    "  o.write(dump(\"Tape Copies\",k,Data[k][\"Tape\"],Units))\n",
    "  Data[k][\"Disk\"] = Data[k][\"Total\"]*DiskCopies[k]\n",
    "  o.write(dump(\"Disk Copies\",k,Data[k][\"Disk\"],Units))\n",
    "  Data[k][\"Cumulative Tape\"] = cumulate(Data[k][\"Tape\"],TapeLifetimes[k])\n",
    "  #o.write(dump(\"Cumulative Tape\",k,Data[k][\"Cumulative Tape\"],Units))\n",
    "  Data[k][\"Cumulative Disk\"] = cumulate(Data[k][\"Disk\"],DiskLifetimes[k])\n",
    "  print (k, \"disk\",Data[k][\"Disk\"],DiskLifetimes[k],cumulate(Data[k][\"Disk\"],DiskLifetimes[k]))\n",
    "  o.write(dump(\"Cumulative Disk\",k,Data[k][\"Cumulative Disk\"],Units ))\n",
    "  o.write(dump(\"Cumulative Tape\",k,Data[k][\"Cumulative Tape\"],Units ))\n",
    "  Data[\"Total\"][\"Cumulative Tape\"] += Data[k][\"Cumulative Tape\"]\n",
    "  Data[\"Total\"][\"Cumulative Disk\"] += Data[k][\"Cumulative Disk\"]\n",
    "  for loc in Splits[\"Disk\"][\"Raw\"]:\n",
    "      Data[loc][\"Cumulative Disk\"] += Data[k][\"Cumulative Disk\"]*Splits[\"Disk\"][k][loc]\n",
    "      Data[loc][\"Cumulative Tape\"] += Data[k][\"Cumulative Tape\"]*Splits[\"Tape\"][k][loc]\n",
    "      print (k,loc,Data[loc][\"Cumulative Disk\"])\n",
    "      print (k,loc,Data[loc][\"Cumulative Tape\"])\n",
    "o.write(dump(\"Cumulative Tape\",\"All\",Data[\"Total\"][\"Cumulative Tape\"],Units ))\n",
    "o.write(dump(\"Cumulative Disk\",\"All\",Data[\"Total\"][\"Cumulative Disk\"],Units ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw various summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Types = [\"ProtoDUNE\",\"FD\",\"ND\",\"Analysis\",\"Total\"]\n",
    "\n",
    "# print (dump(\"Year\",\"Years\",Years,Units))\n",
    "# print (dump(\"Total\",\"Cumulative Tape\",Data[\"Total\"][\"Cumulative Tape\"],Units))\n",
    "# print (dump(\"Total\",\"Cumulative Disk\",Data[\"Total\"][\"Cumulative Disk\"],Units))\n",
    "\n",
    "\n",
    "tex.write(\"\\\\begin{table}\\n\\\\footnotesize\\n \\\\centering \\\\begin{tabular}[h]{crrrrrcccc}\\n\")\n",
    "             \n",
    "s =  \" ,\\t CPU ,\\tWall,\\tWall F/C,\\t\\qquad  ,\\t Tape\\qquad,\\t Tape\\qquad  ,\\t Disk\\qquad  ,\\t Disk\\qquad \\n\"\n",
    "s +=  \"Years,\\t(Mhrs),\\tkSPEC06,\\tkSPEC06,\\tcores,\\t Total(PB),\\tF/C/Collab ,\\t Total(PB) ,\\tF/C/Collab\\n\"\n",
    "\n",
    "table.write(s)\n",
    "print(s)\n",
    "tex.write(s.replace(\"\\n\",\"\\\\\\\\\\n\").replace(\",\\t\",\"&\"))\n",
    "#s = \"Assume present core is %6.3f kSPEC06 \\nCPU # is real CPU, Cores and SPEC06 are Walltime with CPU/Walltime = %5.2f\\n\"%(config[\"kHEPSPEC06PerCPU\"], config[\"Cores\"][\"Efficiency\"])\n",
    "#print (s)\n",
    "#table.write(s)\n",
    "tex.write(\"\\hline\\n\")\n",
    "\n",
    "cores = Data[\"Cores\"][\"Total\"]\n",
    "cpu = Data[\"Total-CPU\"][\"Total\"]\n",
    "disk = Data[\"Total\"][\"Cumulative Disk\"]\n",
    "tape = Data[\"Total\"][\"Cumulative Tape\"]\n",
    "diskF = Data[\"FNAL\"][\"Cumulative Disk\"]\n",
    "tapeF = Data[\"FNAL\"][\"Cumulative Tape\"]\n",
    "diskCE = Data[\"CERN\"][\"Cumulative Disk\"]\n",
    "tapeCE= Data[\"CERN\"][\"Cumulative Tape\"]\n",
    "diskC = Data[\"Collab\"][\"Cumulative Disk\"]\n",
    "tapeC = Data[\"Collab\"][\"Cumulative Tape\"]\n",
    "hep = Data[\"SPEC06\"][\"Total\"]\n",
    "#print (cpu,cores,disk,tape)\n",
    "\n",
    "# CPUused = np.zeros(len(Years))\n",
    "\n",
    "  \n",
    "# for t in config[\"USED\"][\"CPU\"]:\n",
    "        \n",
    "#         for site in config[\"USED\"][\"CPU\"][t]:\n",
    "#             print (t,site)\n",
    "#             for y in range(0,len(Years)):\n",
    "#                 print (t,site,y,config[\"USED\"][\"CPU\"][t][site][y])\n",
    "#                 CPUused[y]+=config[\"USED\"][\"CPU\"][t][site][y]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"\"\n",
    "for i in range(MinYears,len(Years)):  \n",
    "    format = \"%d,\\t%4.0f,\\t%4.0f,\\t%4.0f/%4.0f,\\t %5.0f,\\t %8.1f,\\t %5.1f/%5.1f/%5.1f,\\t %8.1f,\\t %5.1f/%5.1f/%5.1f\\n\"\n",
    "    s += (format)%(Years[i],round(cpu[i]), round(hep[i]),round(hep[i]*.25),round(hep[i]*.75),round(cores[i]),tape[i],tapeF[i],tapeCE[i],tapeC[i],disk[i],diskF[i],diskCE[i],diskC[i])\n",
    "print (s)\n",
    "table.write(s)\n",
    "caption = \"Assume present core is %4.0f SPEC06. CPU number is real CPU. Cores and SPEC06 are Walltime with CPU/Walltime = %5.2f. \"%(config[\"kHEPSPEC06PerCPU\"]*1000, config[\"Cores\"][\"Efficiency\"])\n",
    "caption += \" F means FNAL, C means CERN. Assume CERN storage is only  for ProtoDUNE.\"\n",
    "caption += \" CPU should be divided 25\\% FNAL, 75\\% Collab\"\n",
    "tex.write(s.replace(\"\\n\",\"\\\\\\\\\\n\").replace(\",\",\"&\"))\n",
    "tex.write(\"\\\\end{tabular}\\n\\\\caption{%s}\"%caption)\n",
    "tex.write(\"\\\\normalsize\\n \\\\end{table}\\n\")    \n",
    "\n",
    "asssume = \"Assume present core is %6.3f kSPEC06 \\nCPU # is real CPU, Cores and SPEC06 are Walltime with CPU/Walltime = %5.2f\\n\"%(config[\"kHEPSPEC06PerCPU\"], config[\"Cores\"][\"Efficiency\"])\n",
    "\n",
    "print (s)\n",
    "table.write(s)\n",
    "    \n",
    "s = \"https://github.com/DUNE/Computing-CDR/blob/master/Jupyter/Numbers/\"    \n",
    "print(s)\n",
    "table.write(s)\n",
    "\n",
    "\n",
    "DrawDet(\"Total-CPU\",Years,Data,Types,Units,DetColors,DetLines)\n",
    "DrawDet(\"Cores\",Years,Data,Types,Units,DetColors,DetLines)\n",
    "\n",
    "DrawType(\"Cumulative Tape\",Years,Data,StorageTypes+[\"Total\"],Units,TypeColors,TypeLines)\n",
    "DrawType(\"Cumulative Disk\",Years,Data,StorageTypes+[\"Total\"],Units,TypeColors,TypeLines)\n",
    "# draw twice to fool print\n",
    "DrawType(\"Cumulative Disk\",Years,Data,StorageTypes+[\"Total\"],Units,TypeColors,TypeLines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.close()\n",
    "tex.write(\"\\\\pagebreak\")\n",
    "tex.write(DrawTex(\"Total-CPU.png\",\"CPU time in Wall Hours/year\",\"TotalCPU\"))\n",
    "tex.write(DrawTex(\"Cores.png\",\"Cores needed, including efficiency loss\",\"Cores\"))\n",
    "tex.write(DrawTex(\"Cumulative-Tape.png\",\"Tape tape needs, PB, all types are cumulative over tape lifetime\",\"CumulativeTape\"))\n",
    "tex.write(DrawTex(\"Cumulative-Disk\",\"Disk needs, PB.  Reco and Sim are cumulative over disk lifetime.  Raw and Test have sub-year lifetimes.\",\"CumulativeDisk\"))\n",
    "tex.write(\"\\\\vskip 3 in\\\\pagebreak \\n {\\\\bf Change log:}\\\\\\\\\\n\")\n",
    "for c in config[\"Changes\"]:\n",
    "    tex.write(\"%s\\\\\\\\\"%c)\n",
    "    print (\"%s\\n\"%c)\n",
    "tex.write(\"\\end{document}\")\n",
    "tex.close()\n",
    "o.close()\n",
    "\n",
    "texname = configfile.replace(\"json\",\"tex\")\n",
    "cmd='pdflatex %s'%texname\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
