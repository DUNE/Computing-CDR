\documentclass[../main-v1.tex]{subfiles}
\begin{document}
\section{Simulation Algorithms \hideme{TRJ - draft}}
\label{sec:algo:sim}

\subsection{Beam simulation}
\label{sec:beamsim}

The future \dword{lbnf} beamline is simulated via the \dword{g4lbnf} package, which is based on the systems created for and validated on the \dword{numi} beamlines.  The \dword{proto} beamlines were designed and simulated using the MAD-X framework used at CERN \cite{PhysRevAccelBeams.20.111001}.

\subsubsection{Event Generators}
\label{sec:eventgen}

Extracting physics results from the DUNE experiment requires comparing the observed data with simulations which include detailed simulations of the physics processes under study as well as the response of the detectors.  The physics simulation is performed by the neutrino generators \dword{genie}~\cite{Andreopoulos:2009rq}, NuWRO~\cite{NuWro2012}, GIBUU~\cite{Gallmeister:2016dnq}, NEUT~\cite{Hayato:2009zz}, and others.  Cosmic-ray simulations are performed with \dword{corsika}~\cite{Wentz:2003bp,Dembinski:2020wrp} for detectors on the surface, and MUSUN/MUSIC for detectors deep underground~\cite{Kudryavtsev:2008qh,LBNEDOCDB9673}.  Radiological decays are modeled with BXDECAY0~\cite{Ponkratenko:2000um} and the DUNE-specific RadioGen.

\subsubsection{Detector Simulation}
\label{sec:detsim}

Factorization of the simulation into a generation stage and a detector simulation stage is a common situation in collider experiments, such as ATLAS and CMS.  The fact that the interactions simulated by generators for collider physics happen inside an evacuated beampipe means that the details of the detector geometry and materials are not relevant for most event generation.  Lists of four-vectors of particles emerging from a primary vertex will suffice.  In a neutrino experiment, however, the detector material is the target material, and hence the generators must be aware of the detector geometry and materials, which affects the structure and performance of the generator code.  Currently, \dword{genie}, \dword{corsika}, MUSUN/MUSIC, BXDECAY0 and RadioGen are integrated with \dword{larsoft}.  \dword{genie} is integrated with \dword{garsoft}.


Two classes of simulation of DUNE's detectors exist at the time of writing. 

Parameterized, or ``fast'' detector simulations involve smearing truth-level physics quantities based on expected detector performance metrics, such as acceptance and energy resolution.  These fast simulations are useful when optimizing detector designs, and for engaging physicists outside of the DUNE collaboration.  

Full simulations, on the other hand, are based on detailed geometry models and \dword{geant4}~\cite{Agostinelli:2002hh,Allison:2016lfl}, and are needed for extraction of publication-level results.

In a \dword{geant4}-based simulation of a DUNE detector, \dword{geant4} is used only to simulate the interacting particles from neutrino scatters and other processes of interest, and energy depositions in the active detector material are stored as a distinct data product. 

The propagation of low-energy drifting electrons and scintillation photons, signal induction  and electronics response are then simulated in a separate step.  

Drifting electrons are simulated parametrically using a model based on the measured drift velocity, longitudinal and transverse diffusion coefficients, and a parameterized model of space charge.  This last effect is particularly pronounced at \dword{pdsp} due to the large number of cosmic rays crossing the detector volume, giving rise to distortions in the apparent positions of particles of up to 30~cm.  There are also field distortions due to external imperfections such as the grounded electron diverters in \dword{pdsp}.

Once the electrons drift to the anode plane in wire-based \dwords{lartpc} in the simulation, a detailed two-dimensional model of the wire responses is applied~\cite{Abi:2020mwi}.  The two dimensions are wire number and time, and the effects of induced currents on neighboring wires are included in the simulation.  The electronics response function is folded in to a final model of the observed waveforms.  Simulated waveforms have been compared with real ones and are found to be very similar in \dword{pdsp}.
In the pixel-based \dword{ndlar} and \dword{ndgar}, the electronics simulation is at a simpler level, as the electronics have not been fully designed.


Photon propagation, scattering, absorption and detection are modeled in \dword{larsoft}'s simulation via a photon visibility lookup table, which gives the probability that a photon, emitted in a random direction at a specific location in the active volume of the detector, is detected by a specific photon detector.  The spatial granularity of the lookup table is a few cm.  This lookup table is populated with values that are computed from a \dword{geant4} simulation of scintillation photons in \dword{lar}, with the assumed values of the light attenuation length, the Rayleigh scattering length, the reflectivities of the surfaces inside the detector, and the transparency of the wire planes.  Scintillation photons are not yet simulated in the \dword{ndgar}, where photon detection systems are still under consideration. 

\dword{ndgar} also has a calorimeter and a muon system.  The calorimeter is currently simulated via parameterized responses to the \dword{geant4}-simulated energy deposits, as are the responses to tracks in \dword{ndgarlite} and \dword{sand}.

A large amount of code re-use and sharing via the design of \dword{larsoft} allows for the development of simulation algorithms for \dword{pddp}, the dual-phase far detector, and the Vertical Drift detector proposals.  Only the geometry, the field description, and the anode-plane models need to be updated; the rest of the simulation chain is re-used.


\subsection{ProtoDUNE simulation \hideme{Tingjun? -draft}}

The simulation framework has already been tested successfully in protoDUNE. 

The \dword{pdsp} simulation includes beam particles, cosmic ray interactions and radiological backgrounds. The beam particle species and momentum distributions are from the \dword{geant4} simulation of the H4-VLE beam line at CERN, which consists of $e^{+}$, $\pi^{+}$, $p$, and $K^{+}$ particles at 0.3, 0.5, 1, 2, 3, 6, and 7 GeV/$c$. The cosmic ray interactions are produced with the Corsika generator. Radiological backgrounds, including $^{39}$Ar, $^{42}$Ar, $^{222}$Rn, and $^{85}$Kr, are also simulated using the RadioGen module in \dword{larsoft}. The primary particles are tracked in the liquid argon using the \dword{geant4} package. The ionization electrons are drifted towards the wire planes. The effects of recombination, attenuation and diffusion are simulated. The accumulation of positive ions in the detector modifies the trajectory of ionization electrons and the strength of electric field, which is known as space charge effects and is simulated using the measured distortion and electric field maps. The electronic signal is simulated by convolving the number of electrons reaching each wire plane with the field response and electronics response. The field response is modeled using the GARFIELD package. The electronics response uses the parameterization from the SPICE simulation with the average gain and shaping time measured in the ProtoDUNE charge injection system. %Each event corresponds to a 3 ms readout window with a sampling rate of 0.5$\mu$s per time tick.  The total number of electronic channels is 15,360. 


\section{Photon Detector Simulation}

Photon simulation in large detectors is known to be highly computationally intensive due to the need to trace large number of photons over large distances.  \dword{dune} has several approaches to this problem. 

The sequence for photons simulation is:
\begin{enumerate}
\item particle track simulation in \dword{geant4} to produce the energy deposits along the track
\item  calculate the number of photon/electron emission at each vertex where energy deposits
\item 
simulate the photon transport in the detector (either full simulation or fast simulation)
\item  reconstruct the photons, including the hits and flashes reconstruction
\end{enumerate}
 
In LArSoft, after particles are propagated using GEANT4, energy deposits along tracks are recorded so that the number of electrons and photons generated at each step can be estimated using one of the available  ionization and scintillation methods. Once the number of photons is determined, the fraction of those photons that will actually reach a given photon detector is usually estimated using one of several fast light simulation methods. This procedure is followed for both 128 nm photons (Ar scintillation) and 176 nm photons (Xe scintillation) to account for the wavelength-dependent Rayleigh scattering in the simulation of Xe-doped liquid argon. 
Since a copious number of scintillation photons (25000~ph/MeV at 500~V/cm) is produced in LAr, it is very computationally demanding to individually propagate all photons using GEANT4. Instead,  fast simulations for photons are implemented.
%The photon simulation CPU time per event which depends on what kind of events are simulated and the simulation methods. 
The full \dword{geant4}  photon simulation CPU time per event depends on the energy deposited. 
In the fast simulation methods, using a library,  semi-analytic methods or machine-learning, the CPU time depends on the granularity of the detector. Generally speaking, the performance of the three fast simulations methods is at the same level. 
 
\subsection{Optical Library Method}
This method consists of dividing the cryostat volume into smaller parallelepiped shaped regions called voxels and creating a lookup table that can store the visibility of each photon detector to photons being generated inside a given voxel.
This optical library is created using the full \dword{geant4} simulation to generate photons anywhere inside a given voxel, with random direction and polarization, and then store the fraction of those photons which land on the optically sensitive region (visibility) of a given photon detector, identified within \dword{larsoft}  by its optical channel. When using the fast simulation, \dword{larsoft}  will retrieve the Optical Library and store its information to directly transform the amount of photons generated in a given step along a particle's track into the number of photons landing on each optical channel.
This method can satisfactorily be used as a fast simulation method. Nevertheless, its performance greatly depends on the size of the voxel and the number of photons being generated per voxel. Increasing the number of voxels in a library will improve the description and reduce the bias at the cost of a large increase in memory consumption. Increasing the number of photons per voxel will provide much better statistics and also largely increase the amount of time dedicated to generating the optical library. Special care should be taken for regions with smaller visibilities.

\subsection{Generative Neural Networks}
%Fast simulation with Generative Neural Network
This method relies on a generative neural network  trained on the photon detection system of a detector. The input to the network is the vertex where the photons are emitted, and the output is the visibility of each photon detector.
The generative model can be trained ahead of time using a full  \dword{geant4} optical photon simulation with photons, emitted from random vertices in the detector, and then be frozen to a computable graph and deployed to the production environment (\dword{larsoft}  framework).

When the computable graph is loaded in \dword{larsoft}, it quickly emulates photon transport by  computing the visibility of each photon detector according to the photon emission vertex along the particle’s track.
This method is 20 to 50 times faster than the \dword{geant4} simulation while keeping the same level of detail for particle tracks, such as number of energy depositions, and precision.
The model inference also requires a relatively small amount of memory. The samples for ProtoDUNE-like and DUNE-like geometries show the required memory for the model inference is around 15\% of the \dword{geant4} simulation. Further, this memory use is not directly correlated to the volume of the detectors.

\subsection{Semi-analytical models}
A large number of photons is generated at different points within the cryostat volume and propagated using \dword{geant4}. Gaisser-Hillas functions are fitted to the number of photons reaching the photon detectors as a function of source-detector distance and relative angle, and the resulting parameters are used during event simulation in order to extract the fraction of photons produced at a certain point that arrives at a given sensor.
 
\subsection{Comparison between fast simulation methods}
The semi-analytic model and the use of  optical library models for fast simulation have been compared to the full light simulation in \dword{geant4} for the \dword{sbnd}   experiment. This used a highly segmented and large photon count optical library, created with $\sim$1.6M voxels, with 0.5M photons being generated in each voxel (total of $7.9 \times  10^{11}$ photons), resulting in a file of size 1.2 GB. A similar optical library for the DUNE 1x2x6 geometry (volume of $7 \times 12 times 13.9$ m$^3$) would be prohibitively large.
All DUNE optical libraries produced so far have larger voxels and less photons per voxel being simulated in comparison with the \dword{sbnd}   one which was used as reference for the comparison of the two modes. It has been reported that the optical library struggles to properly describe light signals generated closer to the detectors and more on-axis (up to ~50º). This is a known issue caused by the intrinsic discontinuity of the voxelization schemes. In the protodune optical library, a smoothing of visibilities using neighboring voxels was used trying to minimize this effect.
The semi-analytic model, on the other hand, presents a reduced resolution when going off-axis due to shadowing effects. The influence of shadowing should be minimal for the case of DUNE FD as there are no PMTs in the geometry (in \dword{sbnd}  , the PMTs’ windows reach out to about $\sim$10cm beyond that the X-Arapuca windows), so in the DUNE case we expect  good performance of the semi-analytic model even in the far-off-axis cases.
Specifically for the X-Arapucas in \dword{sbnd}  ,  better performance of the semi-analytic model is expected: better resolution close-on axis (3.6\% vs 5.6\%), with no bias (less than 1\%) in any case, while the optical library is systematically biased (2.5-4.9\%), in particular for the larger/closer signals. This together with the very high memory consumption (of several extra GB) during simulations when using an optical library justifies the current choice of the semi-analytic model as the default for fast simulations in the DUNE FD.


\end{document}