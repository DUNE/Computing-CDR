\chapter{Overview of Computing Model ()}
\label{ch:cm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{broad picture section}
% Need a proper name

SURF -> FNAL -> off site storage -> processing -> analysis

Simulation -> storage -> analysis



\section{Sites and Services}
\label{sec:cm:sites_and_services}  %% fix label according to section

% Some of this should goes to the Site Resources chapter 
% References to APIs and specific technologies
% perhaps even the definitions types of center and site too

This section sets out our ``Sites and Services'' model for using sites for DUNE computing tasks, including sites that participate in OSG or WLCG more generally. Since our requirements are not the same as the LHC experiments, this necessitates a distinct naming scheme to WLCG and ways of mapping our scheme onto the WLCG tier model.

At this stage, DUNE has chosen to express its requirements in terms of services provided by sites. Each site provides networking plus one or more approved DUNE services, which satisfy DUNE's minimum requirements for the service in terms of capacity, quality, and interfaces.

This model allows us to avoid making assumptions about how sites and federations of sites will be organised in the future, as the community evolves away from the strict WLCG tiers model towards DOMA and concepts like data lakes: instead we express our requirements in terms of the services we interact with.

DUNE expects to be able to access services using broadly the same set of APIs as WLCG (eg HTCondor-CE and xroot) and by using common cloud APIs (eg OpenStack and S3). For this reason, sites may be operated using conventional grid technologies, on-premises cloud systems, or commercial cloud services.

Nevertheless, sites do appear in the DUNE computing model, as the atomic unit for operations activity. For example, staff at a site can receive and process tickets, may have a representative at an operations meeting with the technical knowledge to comment on issues as they arise.

In terms of workflows and data management, DUNE does not impose or require any hierarchy or grouping of sites, and assumes that, in general, data may flow between services at any two sites. Having said that, DUNE expects to use network proximity and bandwidth information to guide the efficient transfers of data between services. 

\section{Sites, Federations, and Countries}
\label{sec:cm:federations}

As well as sites, there are two more administrative concepts: federations and countries.

Federations are borrowed from WCLG and represent one or more sites which together pledge a particular amount of capacity to DUNE, and enter their pledges into a system like CRIC. Sites may choose to organise themselves this way as it allows more flexibility in how pleges are met against a background of planned upgrades at sites, unplanned outages etc. 

Countries are represented directly or indirectly at the DUNE Computing Contributions Board, and consist of one or more federations. Broadly, countries map to funding bodies and are the basis of comparison between level of contribution to computing capacity and number of DUNE members.




\section{Types of service}
\label{sec:cm:types_of_service}

We envisage 5 classes of service, on which we will put requirements and request capacity.

\begin{itemize}
    \item Network
    \item DUNE Computing Element
    \item Data Cache
    \item DUNE Storage Element
    \item DUNE Data Archive
\end{itemize}

\subsection{Network}
\label{sec:cm:network}

Networking is needed at all sites, with basic requirements including IPv4 and IPv6 support, an acceptable level of support, and unrestricted connectivity to other sites and on required port ranges. Other DUNE approved services impose further requirements in terms of network capacity which they require,

\subsection{DUNE Computing Element}
\label{sec:cm:dce}

A DUNE Computing Element is a service which gives access to jobs consuming CPU to perform computation. To the operational overhead in working with each site, DUNE will require a minimum standards for

\begin{itemize}
    \item The support level, in terms of whether tickets will be acted 24/7 or only during working hours
    \item The total number of logical processors across the service
    \item The interface used to submit jobs or create virtual machines
    \item Operating system version for grid capacity
    \item Memory and scratch disk per processor
    \item Incoming and outgoing network capacity per processor
    \item Suitable access to a DUNE Storage Element or Data Cache, which allows data intensive jobs to execute without an unacceptably low CPU efficiency
\end{itemize}

We envisage three subclasses within the computing element services aimed at centrally managed data processing, at user or working group data analysis, and at detector simulation. These subclasses have different requirements for network access, and in the case of data analysis, for support level.

\subsection{Data Cache}
\label{sec:cm:data_cache}

Suitable networking. Sufficient nearby DUNE Compute Element capacity to be useful. Not managed by DUNE systems. ``Transparent''. Data loss is equivalent to jobs dying, so a transient which DUNE systems will recover from.

\subsection{DUNE Storage Element}
\label{sec:cm:dse}

The concept of a DUNE Storage Element mirrors that of a DUNE Compute Element. It must be of sufficient capacity, measured in hundreds of TB or PB, for the operational overheard to be worthwhile. It must have a suitable support level, in terms of whether tickets will be acted 24/7 or only during working hours. There must be enough inbound and outbound networking capacity for global data placement operations, and for jobs to write data there or to consume the data already present. In particular, there must be a minimum amount of DUNE Compute Element capacity available nearby, on which DUNE jobs can access the storage service without an unacceptably low CPU efficiency. 

This formulation allows conventional grid sites with CPU and disk storage mixed together in adjacent racks, but also novel regional architectures such as data lakes in which there is sufficient network capacity to link CPU and storage at different locations. At this stage of the project, DUNE does not want to prejudge what will be available at the start of data taking, and does not want to discourage the exploration of new and more efficient ways of providing resources.

\subsection{DUNE Data Archive}

Networking. Cache? Support level? Tape without saying only tape forever.

%The host laboratory is the most important center and during DUNE data %taking will be FNAL. During protoDUNE data taking, both FNAL and CERN %have host laboratory roles. A host laboratory runs central services %for DUNE, makes the largest single contribution in disk and CPU, and %acts as an archive center and user center. This broadly corresponds %to the WLCG Tier-0 concept. 
%
%Archive centers fulfill DUNE’s requirement to have two copies of raw %data on tape (or other archival-quality storage systems), including %one not at the Host Laboratory. It is not essential that archive %centers also have significant amounts of disk and CPU available to %DUNE as they may only be needed for disaster recovery and for %recovering individual lost files. Amongst WLCG sites, archive centers %would be based on the tape archives of Tier-1s, and the concept maps %directly to the DOMA idea of an archive center where disk storage and %CPU may be absent.
%
%Disk centers provide storage managed by DUNE, along with significant %amounts of CPU, and satisfy DUNE’s requirements for the ratio of CPU %to disk, the bandwidth between CPU and disk, and the bandwidth to and %from other participating centers. DUNE does not require 24/7 on call %support for disk centers, but may use the declared support level when %deciding where to place data and where to direct workflows. Disk %centers correspond to WLCG Tier-1 sites or Tier-2 sites with disk, %and to DOMA Data and Compute Centers.
%
%Compute centers provide only CPU capacity, scratch disk associated %with jobs running on worker nodes for the duration of jobs, and %possibly transparent caching (eg Xcache). That is, they do not %provide storage which is managed by DUNE. They do however satisfy %DUNE’s requirements for bandwidth to and from other participating %centers. Compute centers correspond to WLCG Tier-2 sites without %disk, and to DOMA compute centers. 
%
%User centers are used for end user analysis, by people submitting %jobs and managing workflows, and may need to download or stream a %limited amount of data directly from disk centers.


\section{Requirements for computing services}

What we need DUNE services to be able to do, to do the above.



%%%%%%%%%%% notes from 10-29

% Define a minimal "CPU-only" service

% Define a DUNE-managed disk service - how many TB min - requires support. 

% Define a tape service

% Mention possible need for cache for 

%(How do they get the code? cvmfs or container.  