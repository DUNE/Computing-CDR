\documentclass[../main-v1.tex]{subfiles}
\begin{document}
\chapter{Data Formats}
\label{ch:format}

\section{Introduction \hideme{Schellman - draft}} 

\section{Data tiers \hideme{Schellman - add a discussion here}}

\section{I/O formats \hideme{Schellman/Bashyal - draft}}
\dword{dune} has historically used the \dword{root} data format throughout the processing chain.  \dword{root} provides data objects and methods that have been optimized for \dword{hep} applications.  The \dword{larsoft} framework is \dword{root}-compatible and \dword{root} was used for the full processing chain for \dword{protodune} Run 1. 

However, \dword{hep} increasingly uses   machine learning methods that rely on non-\dword{hep} data formats, notably the \dword{hdf5} format.  \dword{hdf5} is designed to save data as arrays of fundamental types, such as integers and floating-point numbers, along with metadata such as group names and dataset names.  \dword{root} files have much more structure.  \dword{root} provides mechanisms for saving and retrieving data in C\raisebox{1pt}{++} classes, provides for automated conversion of data on reading when classes change from one version of user code to the next (schema evolution), and provides structures like trees. \dword{hdf5}'s uniformity of data representation has both advantages and disadvantages. For simple, repetitive data structures, such as the raw waveforms generated by \dword{dune}, the simplicity of \dword{hdf5} is useful.  For interaction reconstruction, \dword{root}'s features for processing complex data objects optimized for \dword{hep} are useful and convenient.  The current \dword{dune} processing chain uses both formats, and the choice has been optimized for each purpose.

In particular, the \dword{protoii} \dword{daq} system now writes raw data in \dword{hdf5} format. The utilization of \dword{hdf5} libraries within the \dword{daq} software allows for multiple processes to write to the same output file asynchronously. This ability is very advantageous when acquiring data from multiple \dword{fd} modules or multiple \dword{nd} subdetectors. The implementation of \dword{hdf5} is being tested %anne within  \dword{pdcoldbox} 
in the \dword{np02} \coldbox at the \dword{cern} with a small prototype of the %anne \dword{pdvd} 
\dword{spvd} \dword{protodune} readout systems. 
\todo{anne: \dword{pdcoldbox} and \dword{pdvd}  aren't standard per the \dword{spvd} CDR }

The \dword{hdf5} format has been integrated successfully with the \dword{art} and \dword{larsoft} frameworks in a manner that allows improved memory management for large data records.  The  input \dword{hdf5} record is parsed and pointers to large data arrays are then made available, sequentially, to the \dword{art}/\dword{root} event processing framework for further processing. Development work to understand if streaming of \dword{hdf5} data over the network is possible or needed for efficient distributed processing of raw data files.

\subsection{Future \hideme{Laycock/Bashyal - need to extend}}
In the near future, the next generation \dword{root} data format, called RNtuple \todo{(NEEDS REFERENCE)} promises even more I/O optimization for \dword{hep} use cases and the \dword{lhc} experiments are expected to migrate to this format on the timescale of \dword{dune}.  Using the same data format as the \dword{lhc} experiments would have clear advantages for \dword{dune}, particularly with regard to enabling interoperability of various elements of the software stack.

\end{document}