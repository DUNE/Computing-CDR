\documentclass[../main-v1.tex]{subfiles}
\begin{document}
\chapter{Information Systems and Monitoring \hideme{5/4 HMS included comments from Anne, Doug and Steve K. }}
\label{ch:mon}

% Create Parameter Values - most #'s will need to be handled this way
% Preface parameter name with the chapter tag
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\FPset{MonEtfOpsPeople}{3.1} % FTE
\FPset{MonEtfDevPeople}{1.0} % FTE
\FPadd\MonEtfTotalPeople\MonEtfOpsPeople\MonEtfDevPeople %FTE

This section %HMS I like describes better anne concerns 
describes the monitoring of services and resources on the grid.  The actual monitoring of individual jobs that are submitted by DUNE 
is provided as part of the Workflow System (see Chapter \ref{ch:wkflow}).

As the global infrastructure is broadly similar to that used by the current \dword{lhc} experiments, DUNE plans to reuse the relevant monitoring tools (\dword{etf}, \dword{perfsonar}) developed for this purpose by the \dword{wlcg} which we cover in this section.  %anne, which we cover in this section.
%These tools are described here. 

%Going forward, DUNE plans to be agile and keep up with upcoming developments in this field. If there is a paradigm change in the resources made available, there may be a need to develop new tools to keep on top of the available resources and display them in a transparent manner. An example can be the widespread deployment of ipv6\cite{bib:ipv6TaskForce} networking requiring possible re-evaluation of various tools for computing. The ETF and perfSonar tools are already ipv6 compatible and can be deployed to test resources offering ipv6 connectivity in either pure or dual-stack mode.
Going forward, DUNE plans to be agile, keep up with upcoming developments in this field, and develop new tools as needed. For example, the widespread deployment of \dword{ipv6}~\cite{bib:ipv6TaskForce} networking may require re-evaluation of some of our computing tools.  The \dword{etf} and \dword{perfsonar} tools are already \dword{ipv6} compatible and can be deployed to test resources offering \dword{ipv6} connectivity in either pure or dual-stack mode.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Tools}
% \begin{dunetable}
% [Monitoring Assumptions]
% {l r l}
% {tab:mon:assumptions}
% {Assumptions for Monitoring}
% Parameter&Value&Comment\\
% ETF personnel&\etfPeople&no comment\\
% \end{dunetable}
\label{sec:mon:xyz}  %% fixhttps://www.overleaf.com/project/5f5a7bb23f29aa0001f211d2 label according to section
\subsection{\dword{cric}} % moved here from IF

DUNE intends to use \dword{cric} \fixme{dword needs def} as a central source of information about sites and their compute and storage services. \dword{cric} is routinely used by ATLAS and CMS with \dword{osg} and other \dword{wlcg} resources, and is also familiar to site administrators. 

An evaluation of \dword{cric} is being done, with information about sites obtained from the configurations of the \dword{osg} pilot factories. This is browsable via the \dword{cric} web dashboard, and also used to generate XML files in the \dword{vo} Feed format required by the \dword{etf} testing framework used for monitoring.
% ref to chapter for this

\subsection{Experiment Test Framework (ETF)}

DUNE jobs run at a number of computer data centers across the grid. Checking the status of these jobs is one way of keeping an eye on whether a given site or resource is functioning normally. Given that issues can and usually do have multiple sources, it is essential to have an independent resource monitoring system to monitor and %anne keep an eye on what is happening to help 
catch issues quickly. %The framework that is being successfully used for this is \dword{etf}. %, is already in the \dword{wlcg}. % WLCG is the ETF system.
\dword{etf}, framework that is being successfully used for this, is the \dword{wlcg} % WLCG is the ETF system.
 Experiments Tests Framework\cite{bib:ETFDoc, bib:ETFStatus}. It  has been known by different names, but the underlying framework remains the same. The \dword{cern} plans to support this framework for as long as \dword{lhc} experiments require availability and reliability metrics from an independent source.
 
\dword{etf} is a system of tools that regularly test all the available resources for different experiments, i.e., \dwords{vo}. It has been developed and run on behalf of the \dword{wlcg} Virtual Organizations ( %anne experiments (VOs) 
 \dwords{vo}) for well over a decade. % now. 
% This framework supports each \dword{vo} running tests customized to the application and systems required by the VOs to enable a true picture (availability, reliability) of the resources available for the VO. The ETF tests run hourly and feed into the MONIT framework which keeps history information and the most recent test logs for enabling debugging and metric measurement.
This framework runs tests customized to the \dword{vo}'s application and systems to provide a true picture of the  available resources and their reliability. The \dword{etf} tests run hourly and feed into the \dword{monit} 
framework, which keeps history information and the most recent test logs to enable debugging and metric measurement.

The \dword{etf} framework currently involves 
\begin{enumerate}
\item high-level functional testing of about 90 hosts defined in the \dword{glideinwms} configuration;
\item dashboard (checkmk) to show results; and
\item plugins conforming to Nagios\footnote{Nagios\textregistered, \url{https://www.nagios.com/}} standard. 
\end{enumerate}

%anne moved up and edited. The framework has been named differently over the years keeping the underlying framework the same. With WLCG based at CERN as it is aimed for the LHC VOs, CERN currently plans to support this framework for as long as LHC exists as there will always be a need for availability and reliability metrics from an independent source.

\begin{comment} see below (anne)
Some customization of the tests has been done, and  further changes being planned, which are :
\begin{enumerate}
    \item Minimal simulation to test that a simulation works on the worker nodes (Done)
    \item Checking if a given worker node has ipv6 networking (Done)
    \item Lightweight test of access to rucio servers from the worker node (ongoing)
\end{enumerate}
\end{comment}

Customized tests are in place to verify %that a minimal simulation works 
a minimal simulation functionality on the worker nodes and to check that a given worker node has \dword{ipv6} networking. A customization to perform a lightweight test of access to  \dword{rucio} servers from the worker node is in progress.

Beyond this, DUNE-specific development will be required from time to time %in keeping 
to synchronize with updates to the framework both from the \dword{etf} / \dword{monit} and the DUNE software ends. %Depending on the requirements we estimate  with 1 
%Doug Benjamin - comment out resource 14-March-22: We estimate that this effort will require  one FTE staff. %will be needed.

%Doug Benjamin - comment out resource estimate 14-March-22: It is expected that \fixme{X} virtual machines with minimum spec \fixme{X} will be required to run the \dword{etf} service, which can be located at any site (e.g., \dword{cern}).

%anne It is expected a
% Commented ETF labor estimate paragraph - 14-Mar-22 Doug Benjamin
%Another three FTE will likely be required to monitor the \dword{etf} results, probably as part of more general computing shifts. This will involve looking at the test results, following up on failing tests and opening tickets for failing resources. Site administrators can also use \dword{etf} tests to understand the performance of their sites. %anne: seems like it says the same thing -- and it can be used (as it is for the LHC VOs) to provide a measure of site performance (availability, reliability).

%Table commendted out 14-Mar-22 Doug Benjamin
%See Table~\ref{tab:mon:assumptions} for a summary. 

\subsection{PerfSonar}

%The core part of DUNE (as with LHC experiments) is to distribute the data taken at the detectors to the different resource centers for analysis. This depends on high-performance networking between the sites providing storage. From experience, identifying and solving issues needs detailed debugging tools. The WLCG solution for this is to develop and deploy a pervasive network monitoring infrastructure to identify and debug issues when they occur.
It is critical to distribute the detector data to the different sites for analysis and storage. This requires both high-performance networking between the sites and sophisticated debugging tools to identify and solve problems that arise. The \dword{wlcg} network monitoring and debugging infrastructure that DUNE will adopt and deploy is \dword{perfsonar}.

\Dword{perfsonar} is an open source toolkit collaboratively developed by %multiple 
groups in Europe and the Americas that keeps a clean separation between network-related and other metrics. %This toolkit 
It is installed on dedicated hardware (\dword{perfsonar} boxes) at %all the sites providing resources to avoid contamination of network metrics with other issues.
each resource site. % that provides resources. 
The data from these \dword{perfsonar} boxes %is 
can be aggregated by a variety of tools and algorithms to %see 
visualize the connectivity in different ways, as described in  in various (kibana, grafana, checkmk, ...) ways, enumerated below.
%\fixme{ideally we'd make these each references and cite them. (anne)}
\begin{enumerate}
    \item \url{https://psetf.opensciencegrid.org/etf/check_mk/index.py}
    \item \url{https://toolkitinfo.opensciencegrid.org/}
    \item \url{https://monit-grafana-open.cern.ch/}
    \item \url{https://atlas-kibana.mwt2.org/s/networking/app/dashboards}
    \item \url{https://perfsonar.uc.ssl-hep.org/}
    \item \url{https://sand-ci.org}
\end{enumerate}

These tools are currently well supported within \dword{wlcg} with %wide expertise being shared between administrators in various regular meetings and conferences. 
expertise shared widely and regularly among administrators.
Given %the expectation 
that networking is a core need for \dword{wlcg} as it is for DUNE, it is anticipated that \dword{perfsonar} %as a network monitoring and debugging tool 
will continue to be supported %into the future.
as long as DUNE requires it.

\section{FIFEMON}\label{is:fifemon}

\todo{add discussion of fifemon and use of elasticsearch and grafana at FNAl}
DUNE relies on the FIFEMON \cite{bib:fifemon}  family of monitoring tools which have been developed at Fermilab over the past
decade or so.  These dashboards show the CPU usage and efficiency and storage usage and traffic of
all the experiments on a user by user basis.

The dashboards are built on open-source technology, and use common ingest tools such as Apache Kafka, Logstash,
and Prometheus to collect data, the Graphite and ElasticSearch data stores to store it, and the Grafana and Kibana 
display utilities to display it.  Grafana is used for static displays, while Kibana has an active search function in which custom graphs can be made using a query language.  

There is information on batch usage by user and aggregate of the whole experiment.  CPU efficiency and memory usage are plotted. In addition storage total usage as well as the volume of reads and writes, as well as the age of files, are visualized.  We also have custom visualizations to display data movement from data center to data center and


%See Table~\ref{mon:ops:needs} for a summary.

% \section{Summary of Assumptions and Resources}
% \subsection{Assumptions}

% ETF support assumption reference

% \subsection{Development needs}

% ETF dev effort, N FTE

% \subsection{Compute resource needs}

% ETF resource requirements list

% \subsection{Operations needs}

% ETF ops effort, M FTE



%\section{Summary of Assumptions and Resource Requirements}

% This section needs summary tables at the end which will be rolled up for the full document
% Please replace #'s in the text with defined parameters and use those in the table (and teXt)
% Place your parameters at the top of the section. 
%

% Commented out table - 14-Mar-22 Doug Benjamin
%\begin{dunetable}
%[Monitoring Assumptions]%{}
%{llrlll}
%{tab:mon:assumptions}
%{Assumptions for monitoring}
%System&Parameter&Value&Units&Comment\\
%FD & Cosmic rate & 5000 & per day&\\
%%ETF personnel&\etfOpsPeople&no comment\\
%\end{dunetable}
%\fixme{(anne) fill in the above table? }



% Commented out table - 14-Mar-22 Doug Benjamin
%\begin{dunetable}
%[Resource requirements for monitoring]
%{llrlll}
%{mon:ops:needs}
%{Resource requirements for monitoring}
%  System & Resource & Value & Units & Timeline&  Comment\\ \toprowrule   
%  ETF Operations & Personnel &\MonEtfOpsPeople  & FTE & 2027-2040&\\ %\colhline % mon-ops-ETF
% ETF Development  & Personnel &\MonEtfDevPeople  & FTE & 2021-2025& \\ %\colhline % mon-dev-ETF
% ETF Total  & Personnel &\num[round-mode=places,round-precision=1]{\MonEtfTotalPeople}  & FTE & 2021-2025& \\ %\colhline % mon-tot-ETF
%      & Storage  &3  & GB&2021-2040& \\ 
%      \colhline % Start new section
%  PerfSonar & Operations &0.1 & FTE &\\ \colhline % mon-ops-PerSonar
%  Row 3 & \daqsamplerate & \\ 
%\end{dunetable}
%\fixme{fix last row of table}
\end{document}